{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents<a id=\"top\"></a>\n",
    "- [Importing Libraries](#import)\n",
    "- [Importing Scraped Data](#data)\n",
    "- [Count Vectorizer Models - No Stemming/Lemmetization, Stop Words Removed](#cvec1)\n",
    "- [TFIDF Vectorizer Models - No Stemming/Lemmetization, Stop Words Removed](#tvec1)\n",
    "- [Function to Tokenize, Lemmatize and Stem Posts](#func)\n",
    "- [Count Vectorizer Models - Lemmetized, Stop Words Removed](#cvec2)\n",
    "- [TFIDF Vectorizer Models - Lemmetized, Stop Words Removed](#tvec2)\n",
    "- [Count Vectorizer Models - Stemmed, Stop Words Removed](#cvec3) <-- Best Performing Vectorized Model\n",
    "- [TFIDF Vectorizer Models - Stemmed, Stop Words Removed](#tvec3)\n",
    "- [Naive Bayes Models](#nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries <a id=\"import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Library tools to turn text in to interpretable DataFrames\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "# Object that uses count vectorizer and Logistic Regrssion as one\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Split data to check train model, Input parameters to create best model\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn import metrics\n",
    "\n",
    "# Importing lemmatizer.\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Importing stemmer.\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Import Tokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Naive Bayes Models \n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Scraped Data <a id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv('./text_df.csv')\n",
    "text_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Unofficial Rewatch Thread - S3E02 \"Run\" **From TV Guide:** Rebecca defends ACN again as another lawsuit looms; Neal could be in trouble after a dangerous leak; Charlie and Leona confront a hostile takeover attempt by Reese\\'s half-siblings; Sloan worries that Don has crossed an ethical line; Hallie regrets a late-night tweet; Maggie weighs the pros and cons of eavesdropping.\\n\\n**From IMDb:** While Rebecca must once again defend ACN during a possible lawsuit, Will tries to protect Neal from the aftermath of the DOD leak; Charlie and Leona deal with a hostile takeover; Sloan worries about Don\\'s involvement with insider information.\\n\\n**Original Discussion Thread [HERE](https://www.reddit.com/r/Thenewsroom/comments/2mips3/episode_discussion_s03e02_run/)**'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['text'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer Models - No Stemming/Lemmetization, Stop Words Removed <a id=\"cvec1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "X = text_df['text']\n",
    "y = text_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split data\n",
    "\n",
    "# Because the sample size is large and I noticed characters were being missed as indicators if they didn't make it \n",
    "# in to the training data, set test_size = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.1, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Pipeline for Count Vectorizer\n",
    "pipe = Pipeline([('cvec', CountVectorizer(stop_words='english')),\n",
    "                 ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8338907469342252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 2500,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Grid Search to create optimum  model\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846711259754738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.87,\n",
       " 'cvec__max_features': 2900,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ReRun Grid Search based on previous results\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2900, 3000, 3100],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.87, .9, .93],\n",
    "    'cvec__ngram_range': [(1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8450390189520625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.87,\n",
       " 'cvec__max_features': 2900,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ReRun Grid Search based on previous results\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2700, 2800, 2900],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.87],\n",
    "    'cvec__ngram_range': [(1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.979933110367893.\n",
      "Test score: 0.865.\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score: {gs.score(X_train, y_train)}.')\n",
    "print(f'Test score: {gs.score(X_test, y_test)}.')\n",
    "\n",
    "# Model is overfit. How to fix? \n",
    "y_pred_test = gs.predict(X_test)\n",
    "y_pred_train = gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data frames to better understand the false predictions\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "train_df['text'] = X_train\n",
    "train_df['actual_y'] = y_train\n",
    "train_df['pred_y'] = y_pred_train\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df['text'] = X_test\n",
    "test_df['actual_y'] = y_test\n",
    "test_df['pred_y'] = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-725a6991b758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_y\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_y\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4375\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4376\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 10"
     ]
    }
   ],
   "source": [
    "# Out of curiosity - Reading the incorrect predictions in the overfit train data. \n",
    "train_df[train_df.pred_y != train_df.actual_y]\n",
    "test_df[test_df.pred_y != test_df.actual_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "just         588\n",
       "season       543\n",
       "episode      487\n",
       "like         416\n",
       "don          326\n",
       "think        326\n",
       "newsroom     299\n",
       "know         298\n",
       "sorkin       283\n",
       "president    278\n",
       "charlie      274\n",
       "time         268\n",
       "west         256\n",
       "wing         252\n",
       "west wing    251\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see what words are showing up. \n",
    "\n",
    "cvec_all_text = CountVectorizer(ngram_range=(1,2), max_features=3700, min_df=2, max_df=0.87, stop_words='english')\n",
    "\n",
    "cvec_all_text.fit(X_train)\n",
    "\n",
    "X_train_cv = cvec_all_text.transform(X_train)\n",
    "\n",
    "X_train_cv = pd.DataFrame(X_train_cv.toarray(),\n",
    "                                 columns = cvec_all_text.get_feature_names())\n",
    "\n",
    "X_train_cv.sum().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorizer Models - No Stemming/Lemmetization, Stop Words Removed <a id=\"tvec1\"></a>\n",
    "\n",
    "[return to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Pipeline for TFID Vectorizer \n",
    "pipe = Pipeline([('tvec', TfidfVectorizer(stop_words='english')),\n",
    "                 ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8651059085841695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.7,\n",
       " 'tvec__max_features': 3000,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'tvec__max_features': [2500, 3000, 3500],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.7, .8, .9],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8651059085841695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.3,\n",
       " 'tvec__max_features': 3000,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'tvec__max_features': [2900, 3000, 3100],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.1, .3, .7],\n",
    "    'tvec__ngram_range': [(1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8651059085841695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.3,\n",
       " 'tvec__max_features': 3000,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'tvec__max_features': [3000],\n",
    "    'tvec__min_df': [2],\n",
    "    'tvec__max_df': [.2, .3, .4],\n",
    "    'tvec__ngram_range': [(1,2), (1,3)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9537346711259754.\n",
      "Test score: 0.875.\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score: {gs.score(X_train, y_train)}.')\n",
    "print(f'Test score: {gs.score(X_test, y_test)}.')\n",
    "\n",
    "# Model is overfit. How to fix? \n",
    "y_pred_test = gs.predict(X_test)\n",
    "y_pred_train = gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Tokenize, Lemmatize and Stem Posts<a id=\"func\"></a>\n",
    "\n",
    "[return to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize, lemmatizing, and stemming function \n",
    "import timeit\n",
    "\n",
    "start = timeit.timeit()\n",
    "\n",
    "print(start)\n",
    "# Instantiating\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def lem_stem(df):\n",
    "    \n",
    "    # Adding columns to DataFrame\n",
    "    df['lem_text'] = None\n",
    "    df['stem_text'] = None\n",
    "    \n",
    "    # Looping through each post\n",
    "    for i in range(df.shape[0]):\n",
    "        \n",
    "        post = df['text'][i]\n",
    "        tokens = tokenizer.tokenize(post.lower()) \n",
    "        \n",
    "        new_post_lem = ''\n",
    "        new_post_stem = ''\n",
    "        \n",
    "        for token in tokens:\n",
    "            lem = lemmatizer.lemmatize(token)\n",
    "            stem = p_stemmer.stem(token)\n",
    "            new_post_lem += ' ' + lem\n",
    "            new_post_stem += ' ' + stem\n",
    "            \n",
    "        df['lem_text'][i] = new_post_lem\n",
    "        df['stem_text'][i] = new_post_stem\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(f'{i} posts complete.')\n",
    "            \n",
    "    return df\n",
    "end = timeit.timeit()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/mags/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 posts complete.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-2d104c418d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# computationally intensive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlem_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# text_df.to_csv('./lem_stem.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-44716eb65fd5>\u001b[0m in \u001b[0;36mlem_stem\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mnew_post_stem\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lem_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_post_lem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stem_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_post_stem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;31m# do the setitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mcacher_needs_updating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_chained_assignment_possible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m         \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_is_chained_assignment_possible\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m                 self._check_setitem_copy(stacklevel=4, t='referant',\n\u001b[0;32m-> 3199\u001b[0;31m                                          force=True)\n\u001b[0m\u001b[1;32m   3200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3201\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[0;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[1;32m   3243\u001b[0m             \u001b[0;31m# the copy weakref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3244\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3245\u001b[0;31m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3246\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3247\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Commenting out calling this code because it was extremely time intensive and I do not want to run it again \n",
    "# by mistake. If I could spend more time on this project, I would like to find a way to do this that is less\n",
    "# computationally intensive.\n",
    "\n",
    "lem_stem(text_df)\n",
    "# text_df.to_csv('./lem_stem.csv')\n",
    "\n",
    "# Saving csv and loading below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_stem_df = pd.read_csv('./lem_stem.csv')\n",
    "lem_stem_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer Models - Lemmetized, Stop Words Removed <a id=\"cvec2\"></a>\n",
    "\n",
    "[return to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lem_stem_df['lem_text']\n",
    "y = lem_stem_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.1, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('cvec', CountVectorizer(stop_words='english')),\n",
    "                 ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8311036789297659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 3000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8311036789297659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.75,\n",
       " 'cvec__max_features': 3000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [2900, 3000, 3100],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.75, .85, .9],\n",
    "    'cvec__ngram_range': [(1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8355629877369007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.15,\n",
       " 'cvec__max_features': 3000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [3000],\n",
    "    'cvec__min_df': [2],\n",
    "    'cvec__max_df': [.15, .35, .75],\n",
    "    'cvec__ngram_range': [(1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8355629877369007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.15,\n",
       " 'cvec__max_features': 3000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [3000],\n",
    "    'cvec__min_df': [2],\n",
    "    'cvec__max_df': [.14, .15, .16],\n",
    "    'cvec__ngram_range': [(1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9788182831661093.\n",
      "Test score: 0.855.\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score: {gs.score(X_train, y_train)}.')\n",
    "print(f'Test score: {gs.score(X_test, y_test)}.')\n",
    "\n",
    "# Model accuracy is almost identical to non lemmetized model.\n",
    "y_pred_test = gs.predict(X_test)\n",
    "y_pred_train = gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorizer Models - Lemmetized, Stop Words Removed <a id=\"tvec2\"></a>\n",
    "\n",
    "[return to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('tvec', TfidfVectorizer(stop_words='english')),\n",
    "                 ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8584169453734671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.3,\n",
       " 'tvec__max_features': 3000,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'tvec__max_features': [2000, 3000],\n",
    "    'tvec__min_df': [2],\n",
    "    'tvec__max_df': [.2, .3, .4],\n",
    "    'tvec__ngram_range': [(1,2), (1,3)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8606465997770345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.25,\n",
       " 'tvec__max_features': 3100,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'tvec__max_features': [2900, 3000, 3100],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.25, .3],\n",
    "    'tvec__ngram_range': [(1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8606465997770345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.25,\n",
       " 'tvec__max_features': 3100,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'tvec__max_features': [3100, 3200, 3300],\n",
    "    'tvec__min_df': [2],\n",
    "    'tvec__max_df': [.1, .2, .25],\n",
    "    'tvec__ngram_range': [(1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9559643255295429.\n",
      "Test score: 0.875.\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score: {gs.score(X_train, y_train)}.')\n",
    "print(f'Test score: {gs.score(X_test, y_test)}.')\n",
    "\n",
    "# Model accuracy is almost identical to non lemmetized model, just slightly better\n",
    "y_pred_test = gs.predict(X_test)\n",
    "y_pred_train = gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer Models - Stemmed, Stop Words Removed <a id=\"cvec3\"></a>\n",
    "\n",
    "[return to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lem_stem_df['stem_text']\n",
    "y = lem_stem_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.1, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('cvec', CountVectorizer(stop_words='english')),\n",
    "                 ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8327759197324415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.3,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [2000, 3000, 4000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.05, .15, .3],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.23,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [3500, 4000, 4500],\n",
    "    'cvec__min_df': [2],\n",
    "    'cvec__max_df': [.23, .3, .35],\n",
    "    'cvec__ngram_range': [(1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8344481605351171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.23,\n",
       " 'cvec__max_features': 4100,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [4000, 4100],\n",
    "    'cvec__min_df': [2],\n",
    "    'cvec__max_df': [.21, .23, .25],\n",
    "    'cvec__ngram_range': [(1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9849498327759197.\n",
      "Test score: 0.875.\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score: {gs.score(X_train, y_train)}.')\n",
    "print(f'Test score: {gs.score(X_test, y_test)}.')\n",
    "\n",
    "# Best version of three very similar models\n",
    "y_pred_test = gs.predict(X_test)\n",
    "y_pred_train = gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorizer Models - Stemmed, Stop Words Removed <a id=\"tvec3\"></a>\n",
    "\n",
    "[return to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('tvec', TfidfVectorizer(stop_words='english')),\n",
    "                 ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8578595317725752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.3,\n",
       " 'tvec__max_features': 3100,\n",
       " 'tvec__min_df': 3,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'tvec__max_features': [2600, 3100, 3600],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.2, .25, .3],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8578595317725752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.29,\n",
       " 'tvec__max_features': 2950,\n",
       " 'tvec__min_df': 3,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'tvec__max_features': [2700, 2800, 2950],\n",
    "    'tvec__min_df': [3],\n",
    "    'tvec__max_df': [.27, .28, .29],\n",
    "    'tvec__ngram_range': [(1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.955406911928651.\n",
      "Test score: 0.875.\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score: {gs.score(X_train, y_train)}.')\n",
    "print(f'Test score: {gs.score(X_test, y_test)}.')\n",
    "\n",
    "# Identical performance to lemmetized data\n",
    "y_pred_test = gs.predict(X_test)\n",
    "y_pred_train = gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model <a id=\"nb\"></a>\n",
    "\n",
    "[return to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models to run\n",
    "I will be creating 6 total Naive Bayes models to compare based on my best found hyperparameters for each of the 6 types of Vectorized models that I ran. I will be running MultinomialNB on my count vectorizer models and GaussianNB on my TFIDF models.\n",
    "\n",
    "- Count Vectorizer - No Stemming/Lemmetization, Stop Words Removed\n",
    "    - {'cvec__max_df': 0.87, 'cvec__max_features': 2900, 'cvec__min_df': 3, 'cvec__ngram_range': (1, 2)}\n",
    "    - Train accuracy score = 98.0%\n",
    "    - Test accuracy score = 86.5%\n",
    "- TFIDF Vectorizer - No Stemming/Lemmetization, Stop Words Removed\n",
    "    - {'tvec__max_df': 0.3, 'tvec__max_features': 3000, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 2)}\n",
    "    - Train accuracy score = 95.3%\n",
    "    - Test accuracy score = 87.5%\n",
    "- Count Vectorizer - Lemmetized, Stop Words Removed\n",
    "    - {'cvec__max_df': 0.15, 'cvec__max_features': 3000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2)}\n",
    "    - Train accuracy score = 97.9%\n",
    "    - Test accuracy score = 85.5%\n",
    "- TFIDF Vectorizer - Lemmetized, Stop Words Removed\n",
    "    - {'tvec__max_df': 0.25, 'tvec__max_features': 3100, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 2)}\n",
    "    - Train accuracy score = 95.6%\n",
    "    - Test accuracy score = 87.5%\n",
    "- Count Vectorizer - Stemmed, Stop Words Removed <-- Best Performing Vectorized Model\n",
    "    - {'cvec__max_df': 0.23, 'cvec__max_features': 4100, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2)}\n",
    "    - Train accuracy score = 98.5%\n",
    "    - Test accuracy score = 87.5%\n",
    "- TFIDF Vectorizer - Stemmed, Stop Words Removed\n",
    "    - {'tvec__max_df': 0.29, 'tvec__max_features': 2950, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 2)}\n",
    "    - Train accuracy score = 95.5%\n",
    "    - Test accuracy score = 87.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9241917502787068\n",
      "Test score: 0.885\n"
     ]
    }
   ],
   "source": [
    "X = lem_stem_df['text']\n",
    "y = lem_stem_df['class']\n",
    "\n",
    "vect = CountVectorizer(max_df=0.87, max_features=2900, ngram_range=(1,2), stop_words='english')\n",
    "vect.fit(X)\n",
    "\n",
    "X_transform = vect.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y, stratify=y, test_size=0.1, random_state=30)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "print(f'Train score: {metrics.accuracy_score(y_train, nb.predict(X_train))}')\n",
    "print(f'Test score: {metrics.accuracy_score(y_test, nb.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9437012263099219\n",
      "Test score: 0.775\n"
     ]
    }
   ],
   "source": [
    "tvect = TfidfVectorizer(max_df=0.3, max_features=3000, min_df=2, ngram_range=(1,2), stop_words='english')\n",
    "tvect.fit(X)\n",
    "\n",
    "X_transform = tvect.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y, stratify=y, test_size=0.1, random_state=30)\n",
    "\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "gb = GaussianNB()\n",
    "gb.fit(X_train_dense, y_train)\n",
    "\n",
    "print(f'Train score: {metrics.accuracy_score(y_train, gb.predict(X_train_dense))}')\n",
    "print(f'Test score: {metrics.accuracy_score(y_test, gb.predict(X_test_dense))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9319955406911928\n",
      "Test score: 0.885\n"
     ]
    }
   ],
   "source": [
    "X = lem_stem_df['lem_text']\n",
    "y = lem_stem_df['class']\n",
    "\n",
    "vect = CountVectorizer(max_df=0.15, max_features=3000, min_df=2, ngram_range=(1,2), stop_words='english')\n",
    "vect.fit(X)\n",
    "\n",
    "X_transform = vect.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y, stratify=y, test_size=0.1, random_state=30)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "print(f'Train score: {metrics.accuracy_score(y_train, nb.predict(X_train))}')\n",
    "print(f'Test score: {metrics.accuracy_score(y_test, nb.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9453734671125975\n",
      "Test score: 0.755\n"
     ]
    }
   ],
   "source": [
    "tvect = TfidfVectorizer(max_df=0.25, max_features=3100, min_df=2, ngram_range=(1,2), stop_words='english')\n",
    "tvect.fit(X)\n",
    "\n",
    "X_transform = tvect.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y, stratify=y, test_size=0.1, random_state=30)\n",
    "\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "gb = GaussianNB()\n",
    "gb.fit(X_train_dense, y_train)\n",
    "\n",
    "print(f'Train score: {metrics.accuracy_score(y_train, gb.predict(X_train_dense))}')\n",
    "print(f'Test score: {metrics.accuracy_score(y_test, gb.predict(X_test_dense))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9375696767001115\n",
      "Test score: 0.885\n"
     ]
    }
   ],
   "source": [
    "X = lem_stem_df['stem_text']\n",
    "y = lem_stem_df['class']\n",
    "\n",
    "vect = CountVectorizer(max_df=0.23, max_features=4100, min_df=2, ngram_range=(1,2), stop_words='english')\n",
    "vect.fit(X)\n",
    "\n",
    "X_transform = vect.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y, stratify=y, test_size=0.1, random_state=30)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "print(f'Train score: {metrics.accuracy_score(y_train, nb.predict(X_train))}')\n",
    "print(f'Test score: {metrics.accuracy_score(y_test, nb.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9509476031215162\n",
      "Test score: 0.74\n"
     ]
    }
   ],
   "source": [
    "tvect = TfidfVectorizer(max_df=0.29, max_features=2950, min_df=3, ngram_range=(1,2), stop_words='english')\n",
    "tvect.fit(X)\n",
    "\n",
    "X_transform = tvect.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y, stratify=y, test_size=0.1, random_state=30)\n",
    "\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "gb = GaussianNB()\n",
    "gb.fit(X_train_dense, y_train)\n",
    "\n",
    "print(f'Train score: {metrics.accuracy_score(y_train, gb.predict(X_train_dense))}')\n",
    "print(f'Test score: {metrics.accuracy_score(y_test, gb.predict(X_test_dense))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
